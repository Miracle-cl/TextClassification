{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(0) # won't use cuda:0 to initialize\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import DistilBertConfig, DistilBertTokenizer, DistilBertModel, AdamW, DistilBertPreTrainedModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertForClassification(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.distilbert = DistilBertModel(config)\n",
    "        # self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
    "        self.classifier = nn.Linear(config.dim, config.num_labels)\n",
    "        self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
    "\n",
    "        # self.init_weights() # change initial weights\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, hidden_size)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, hidden_size)\n",
    "        pooled_output = F.relu(self.pre_classifier(pooled_output))  # (bs, hidden_size)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "    \n",
    "model_path = './distilbert_models/'\n",
    "config = DistilBertConfig.from_json_file(os.path.join(model_path, 'config.json'))\n",
    "model = DistilBertForClassification(config)\n",
    "# state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'), map_location='cpu')\n",
    "state_dict = torch.load(os.path.join(model_path, 'pytorch_model.bin'))\n",
    "model.load_state_dict(state_dict)\n",
    "tokenizer = DistilBertTokenizer(os.path.join(model_path, 'vocab.txt'), do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tok/vocab.txt', './tok/special_tokens_map.json', './tok/added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('./tok/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tok/vocab.txt',)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_vocabulary('./tok/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tok/vocab.txt', './tok/special_tokens_map.json', './tok/added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"./distilbert_models/\"\n",
    "tokenizer1 = DistilBertTokenizer.from_pretrained(output_dir, do_lower_case=True)\n",
    "tokenizer1.save_pretrained('./tok/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0) # , add_special_tokens=True\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"./distilbert_models/\"\n",
    "tokenizer1 = DistilBertTokenizer.from_pretrained(output_dir, do_lower_case=True)\n",
    "input_ids1 = torch.tensor(tokenizer1.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0) # , add_special_tokens=True\n",
    "input_ids1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "with open('./e3_distilbert_process_data.pkl', 'rb') as f:\n",
    "    bert_process_data = pickle.load(f)\n",
    "    \n",
    "# train_inputs = bert_process_data['train_inputs']\n",
    "# train_labels = bert_process_data['train_labels']\n",
    "# train_masks = bert_process_data['train_masks']\n",
    "\n",
    "val_inputs = bert_process_data['val_inputs']\n",
    "val_labels = bert_process_data['val_labels']\n",
    "val_masks = bert_process_data['val_masks']\n",
    "\n",
    "test_inputs, test_masks = bert_process_data['test_inputs'], bert_process_data['test_masks']\n",
    "test_labels, test_lnis = bert_process_data['test_labels'], bert_process_data['test_lnis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5849"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "# train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "# train_sampler = RandomSampler(train_data)\n",
    "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertForClassification(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # self.distilbert = DistilBertModel(config)\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
    "        self.classifier = nn.Linear(config.dim, config.num_labels)\n",
    "        self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
    "\n",
    "        # self.init_weights() # change initial weights\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, hidden_size)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, hidden_size)\n",
    "        pooled_output = F.relu(self.pre_classifier(pooled_output))  # (bs, hidden_size)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "    \n",
    "#     def load_pretrain_wights(self):\n",
    "#         self.distilbert.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "configuration = DistilBertConfig(num_labels=133)\n",
    "model = DistilBertForClassification(configuration)\n",
    "# model.from_pretrained('distilbert-base-uncased')\n",
    "params = list(model.named_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert.transformer.layer.0.attention.q_lin.bias torch.Size([768]) True tensor([ 0.5412, -0.2970, -0.4073,  0.3460, -0.2974,  0.4035,  0.0176,  0.2931,\n",
      "         0.2445, -0.1061], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "for p in params[5:21]:\n",
    "    print(p[0], p[1].size(), p[1].requires_grad, p[1][:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_params(model):\n",
    "    params = list(model.named_parameters())\n",
    "    p = params[5]\n",
    "    print(p[0], p[1].size(), p[1].requires_grad, p[1][:10])\n",
    "    p = params[6]\n",
    "    print(p[0], p[1].size(), p[1].requires_grad, p[1][0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): DistilBertForClassification(\n",
       "    (distilbert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (classifier): Linear(in_features=768, out_features=133, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing a DistilBERT configuration\n",
    "# configuration = DistilBertConfig()\n",
    "configuration = DistilBertConfig(num_labels=133)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "model = DistilBertForClassification(configuration)\n",
    "model.load_pretrain_wights()\n",
    "model = nn.DataParallel(model, device_ids=[0, 1], dim=0)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertForClassification(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, hidden_size=768, num_labels=133, dropout_prob=0.5):\n",
    "        super().__init__(config)\n",
    "        # self.distilbert = DistilBertModel(config)\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.pre_classifier = nn.Linear(hidden_size, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        # self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, hidden_size)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, hidden_size)\n",
    "        pooled_output = F.relu(self.pre_classifier(pooled_output))  # (bs, hidden_size)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config\n",
    "# configuration = DistilBertConfig()\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = DistilBertForClassification(configuration)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": null,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"dim\": 768,\n",
      "  \"do_sample\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\",\n",
      "    \"77\": \"LABEL_77\",\n",
      "    \"78\": \"LABEL_78\",\n",
      "    \"79\": \"LABEL_79\",\n",
      "    \"80\": \"LABEL_80\",\n",
      "    \"81\": \"LABEL_81\",\n",
      "    \"82\": \"LABEL_82\",\n",
      "    \"83\": \"LABEL_83\",\n",
      "    \"84\": \"LABEL_84\",\n",
      "    \"85\": \"LABEL_85\",\n",
      "    \"86\": \"LABEL_86\",\n",
      "    \"87\": \"LABEL_87\",\n",
      "    \"88\": \"LABEL_88\",\n",
      "    \"89\": \"LABEL_89\",\n",
      "    \"90\": \"LABEL_90\",\n",
      "    \"91\": \"LABEL_91\",\n",
      "    \"92\": \"LABEL_92\",\n",
      "    \"93\": \"LABEL_93\",\n",
      "    \"94\": \"LABEL_94\",\n",
      "    \"95\": \"LABEL_95\",\n",
      "    \"96\": \"LABEL_96\",\n",
      "    \"97\": \"LABEL_97\",\n",
      "    \"98\": \"LABEL_98\",\n",
      "    \"99\": \"LABEL_99\",\n",
      "    \"100\": \"LABEL_100\",\n",
      "    \"101\": \"LABEL_101\",\n",
      "    \"102\": \"LABEL_102\",\n",
      "    \"103\": \"LABEL_103\",\n",
      "    \"104\": \"LABEL_104\",\n",
      "    \"105\": \"LABEL_105\",\n",
      "    \"106\": \"LABEL_106\",\n",
      "    \"107\": \"LABEL_107\",\n",
      "    \"108\": \"LABEL_108\",\n",
      "    \"109\": \"LABEL_109\",\n",
      "    \"110\": \"LABEL_110\",\n",
      "    \"111\": \"LABEL_111\",\n",
      "    \"112\": \"LABEL_112\",\n",
      "    \"113\": \"LABEL_113\",\n",
      "    \"114\": \"LABEL_114\",\n",
      "    \"115\": \"LABEL_115\",\n",
      "    \"116\": \"LABEL_116\",\n",
      "    \"117\": \"LABEL_117\",\n",
      "    \"118\": \"LABEL_118\",\n",
      "    \"119\": \"LABEL_119\",\n",
      "    \"120\": \"LABEL_120\",\n",
      "    \"121\": \"LABEL_121\",\n",
      "    \"122\": \"LABEL_122\",\n",
      "    \"123\": \"LABEL_123\",\n",
      "    \"124\": \"LABEL_124\",\n",
      "    \"125\": \"LABEL_125\",\n",
      "    \"126\": \"LABEL_126\",\n",
      "    \"127\": \"LABEL_127\",\n",
      "    \"128\": \"LABEL_128\",\n",
      "    \"129\": \"LABEL_129\",\n",
      "    \"130\": \"LABEL_130\",\n",
      "    \"131\": \"LABEL_131\",\n",
      "    \"132\": \"LABEL_132\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_100\": 100,\n",
      "    \"LABEL_101\": 101,\n",
      "    \"LABEL_102\": 102,\n",
      "    \"LABEL_103\": 103,\n",
      "    \"LABEL_104\": 104,\n",
      "    \"LABEL_105\": 105,\n",
      "    \"LABEL_106\": 106,\n",
      "    \"LABEL_107\": 107,\n",
      "    \"LABEL_108\": 108,\n",
      "    \"LABEL_109\": 109,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_110\": 110,\n",
      "    \"LABEL_111\": 111,\n",
      "    \"LABEL_112\": 112,\n",
      "    \"LABEL_113\": 113,\n",
      "    \"LABEL_114\": 114,\n",
      "    \"LABEL_115\": 115,\n",
      "    \"LABEL_116\": 116,\n",
      "    \"LABEL_117\": 117,\n",
      "    \"LABEL_118\": 118,\n",
      "    \"LABEL_119\": 119,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_120\": 120,\n",
      "    \"LABEL_121\": 121,\n",
      "    \"LABEL_122\": 122,\n",
      "    \"LABEL_123\": 123,\n",
      "    \"LABEL_124\": 124,\n",
      "    \"LABEL_125\": 125,\n",
      "    \"LABEL_126\": 126,\n",
      "    \"LABEL_127\": 127,\n",
      "    \"LABEL_128\": 128,\n",
      "    \"LABEL_129\": 129,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_130\": 130,\n",
      "    \"LABEL_131\": 131,\n",
      "    \"LABEL_132\": 132,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_77\": 77,\n",
      "    \"LABEL_78\": 78,\n",
      "    \"LABEL_79\": 79,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_80\": 80,\n",
      "    \"LABEL_81\": 81,\n",
      "    \"LABEL_82\": 82,\n",
      "    \"LABEL_83\": 83,\n",
      "    \"LABEL_84\": 84,\n",
      "    \"LABEL_85\": 85,\n",
      "    \"LABEL_86\": 86,\n",
      "    \"LABEL_87\": 87,\n",
      "    \"LABEL_88\": 88,\n",
      "    \"LABEL_89\": 89,\n",
      "    \"LABEL_9\": 9,\n",
      "    \"LABEL_90\": 90,\n",
      "    \"LABEL_91\": 91,\n",
      "    \"LABEL_92\": 92,\n",
      "    \"LABEL_93\": 93,\n",
      "    \"LABEL_94\": 94,\n",
      "    \"LABEL_95\": 95,\n",
      "    \"LABEL_96\": 96,\n",
      "    \"LABEL_97\": 97,\n",
      "    \"LABEL_98\": 98,\n",
      "    \"LABEL_99\": 99\n",
      "  },\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_labels\": 133,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=133, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DistilBertForClassification(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        # self.distilbert = DistilBertModel(config)\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
    "        self.classifier = nn.Linear(config.dim, config.num_labels)\n",
    "        self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
    "\n",
    "        # self.init_weights() # change initial weights\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, head_mask=None, inputs_embeds=None, labels=None):\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, hidden_size)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, hidden_size)\n",
    "        pooled_output = F.relu(self.pre_classifier(pooled_output))  # (bs, hidden_size)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "output_dir = \"./distilbert_models/\"\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(output_dir, do_lower_case=True, add_special_tokens=True)\n",
    "device = torch.device('cpu')\n",
    "model = DistilBertForClassification.from_pretrained(output_dir)\n",
    "print(model.config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, device, epoch, train_dataloader, validation_dataloader, \n",
    "                criterion, optimizer, clip=5.):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    t0 = time.time()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader, 1):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        loss = criterion(outputs, b_labels)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        # scheduler.step()\n",
    "        if step % 1000 == 0:\n",
    "            # print loss info every 20 Iterations\n",
    "            log_str = \"Epoch : {} , Iteration : {} , Time : {:.2f} , TrainLoss : {:.4f}\".format \\\n",
    "                        (epoch, step, time.time()-t0, train_loss/step)\n",
    "            print(log_str)\n",
    "            t0 = time.time()\n",
    "            break\n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(validation_dataloader, 1):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "            loss = criterion(outputs, b_labels)\n",
    "            eval_loss += loss.item()\n",
    "        eval_loss /= len(validation_dataloader)\n",
    "\n",
    "    return model, optimizer, train_loss, eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WEIGHTS_NAME, CONFIG_NAME\n",
    "import os\n",
    "\n",
    "def save_transformers(model, tokenizer):\n",
    "    output_dir = \"./models/\"\n",
    "\n",
    "    # Step 1: Save a model, configuration and vocabulary that you have fine-tuned\n",
    "    # If we have a distributed model, save only the encapsulated model\n",
    "    # (it was wrapped in PyTorch DistributedDataParallel or DataParallel)\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "    # If we save using the predefined names, we can load using `from_pretrained`\n",
    "    output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "    output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    model.config.to_json_file(output_config_file)\n",
    "    tokenizer.save_vocabulary(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hasattr(model, 'module'))\n",
    "# model_to_save = model.module\n",
    "# print(model_to_save.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 , Iteration : 1000 , Time : 99.68 , TrainLoss : 0.0000\n",
      ">> Epoch : 1 , TrainLoss : 0.0435 , EvalLoss : 0.0334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "clip = 2.0\n",
    "# save_path = './ft_distilbert_0219.pt'\n",
    "best_eval_loss = float('inf')\n",
    "for epoch in range(1, 1+n_epochs):\n",
    "    model, optimizer, train_loss, eval_loss = train_epoch(model, device, epoch, \n",
    "                                                          train_dataloader, validation_dataloader, \n",
    "                                                          criterion, optimizer, clip=clip)\n",
    "\n",
    "    print(\">> Epoch : {} , TrainLoss : {:.4f} , EvalLoss : {:.4f}\\n\".format \\\n",
    "          (epoch, train_loss, eval_loss))\n",
    "\n",
    "    if eval_loss < best_eval_loss:\n",
    "        best_eval_loss = eval_loss\n",
    "        save_transformers(model, tokenizer)\n",
    "        # torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = \"./distilbert_models/\"\n",
    "# model = DistilBertForClassification.from_pretrained(output_dir)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_res(model, data_loader, device):\n",
    "    model.eval()\n",
    "    y_true = None\n",
    "    y_pred = None\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "            \n",
    "            if y_true is None:\n",
    "                y_true = b_labels\n",
    "            else:\n",
    "                y_true = torch.cat((y_true, b_labels), 0)\n",
    "            # outputs = model(seqs, seq_lens)\n",
    "\n",
    "            if y_pred is None:\n",
    "                y_pred = outputs\n",
    "            else:\n",
    "                y_pred = torch.cat((y_pred, outputs), 0)\n",
    "            # break\n",
    "\n",
    "    print(y_true.size(), y_pred.size())\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "    return y_true.cpu().numpy(), y_pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_column_wise_auc(y_true, y_pred):\n",
    "    assert y_true.shape[1] == y_pred.shape[1],'Arrays must have the same dimension'\n",
    "    list_of_aucs = []\n",
    "    for column in range(y_true.shape[1]):\n",
    "        #print(sum(y_true[:,column]), sum(y_pred[:,column]))\n",
    "        if sum(y_true[:,column]) == 0:\n",
    "            continue\n",
    "        list_of_aucs.append(roc_auc_score(y_true[:,column],y_pred[:,column]))\n",
    "    # print(list_of_aucs)\n",
    "    return np.array(list_of_aucs).mean(), len((list_of_aucs))\n",
    "\n",
    "def fit_active_value(s1, active_value):\n",
    "    # return np.round(s1)\n",
    "    return (s1 > active_value).astype(int)\n",
    "\n",
    "def cut_max_num(s1, max_num):\n",
    "    max_ids = np.argsort(s1)[-max_num:]\n",
    "    s3 = np.zeros_like(s1)\n",
    "    # for i in max_ids:\n",
    "    #     s3[i] = 1\n",
    "    s3[max_ids] = 1\n",
    "    return s3\n",
    "\n",
    "def cal_avg_p_r(arr_true, arr_pred, max_num=6, active_value=0.05):\n",
    "    ps, rs = [], []\n",
    "    for i in range(arr_true.shape[0]):\n",
    "        t1, s1 = arr_true[i], arr_pred[i]\n",
    "        if sum(t1) <= 0:\n",
    "            continue\n",
    "        s2 = fit_active_value(s1, active_value)\n",
    "        if sum(s2) > max_num:\n",
    "            s2 = cut_max_num(s1, max_num)\n",
    "        # if sum(s2) > 4:\n",
    "        #     s2 = get_maxf_adj(s1, s2, adj_phrase_map, phrase_prob, cannot_be_only)\n",
    "        # s2 = fit_threshold(s1, thresholds)\n",
    "\n",
    "        p, r = precision_score(t1, s2), recall_score(t1, s2)\n",
    "        ps.append(p)\n",
    "        rs.append(r)\n",
    "    return np.average(ps), np.average(rs), len(ps), ps, rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48096, 133]) torch.Size([48096, 133])\n"
     ]
    }
   ],
   "source": [
    "val_true, val_pred = predict_res(model, validation_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([93581, 133]) torch.Size([93581, 133])\n"
     ]
    }
   ],
   "source": [
    "# test_dataloader\n",
    "test_true, test_pred = predict_res(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9758983430744022, (0.983780945344874, 129))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_auc = roc_auc_score(val_true, val_pred)\n",
    "test_auc = mean_column_wise_auc(test_true, test_pred)\n",
    "val_auc, test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5365099661787537, 0.9350487599536378, 48096)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pr = cal_avg_p_r(val_true, val_pred, max_num=6, active_value=0.02)\n",
    "val_pr[:3] # (0.5365099661787537, 0.9350487599536378, 48096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5380684469425774, 0.9606396919874013, 93581)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pr = cal_avg_p_r(test_true, test_pred, max_num=6, active_value=0.02)\n",
    "test_pr[:3] # (0.5380684469425774, 0.9606396919874013, 93581)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": null,\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"dim\": 768,\n",
       "  \"do_sample\": false,\n",
       "  \"dropout\": 0.1,\n",
       "  \"eos_token_ids\": 0,\n",
       "  \"finetuning_task\": null,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\",\n",
       "    \"3\": \"LABEL_3\",\n",
       "    \"4\": \"LABEL_4\",\n",
       "    \"5\": \"LABEL_5\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"is_decoder\": false,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2,\n",
       "    \"LABEL_3\": 3,\n",
       "    \"LABEL_4\": 4,\n",
       "    \"LABEL_5\": 5\n",
       "  },\n",
       "  \"length_penalty\": 1.0,\n",
       "  \"max_length\": 20,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"num_beams\": 1,\n",
       "  \"num_labels\": 6,\n",
       "  \"num_return_sequences\": 1,\n",
       "  \"output_attentions\": false,\n",
       "  \"output_hidden_states\": false,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pruned_heads\": {},\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"repetition_penalty\": 1.0,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"temperature\": 1.0,\n",
       "  \"top_k\": 50,\n",
       "  \"top_p\": 1.0,\n",
       "  \"torchscript\": false,\n",
       "  \"use_bfloat16\": false,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = DistilBertConfig(num_labels=6)\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing a model from the configuration\n",
    "model = DistilBertForClassification(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WEIGHTS_NAME, CONFIG_NAME\n",
    "import os\n",
    "output_dir = \"./models/\"\n",
    "\n",
    "# Step 1: Save a model, configuration and vocabulary that you have fine-tuned\n",
    "\n",
    "# If we have a distributed model, save only the encapsulated model\n",
    "# (it was wrapped in PyTorch DistributedDataParallel or DataParallel)\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "\n",
    "# If we save using the predefined names, we can load using `from_pretrained`\n",
    "output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_to_save.state_dict(), output_model_file)\n",
    "model_to_save.config.to_json_file(output_config_file)\n",
    "# tokenizer.save_vocabulary(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.layer.0.attention.k_lin.weight torch.Size([768, 768]) tensor([ 0.0342, -0.0546, -0.0055,  0.0043,  0.0282, -0.0536,  0.0542,  0.0100,\n",
      "        -0.0263,  0.0193], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "params = list(model.named_parameters())\n",
    "for p in params[6:21]:\n",
    "    #print(p[0], p[1].size(), p[1][:10])\n",
    "    print(p[0], p[1].size(), p[1][0, :10])\n",
    "    \n",
    "    break\n",
    "    \n",
    "# transformer.layer.0.attention.q_lin.bias torch.Size([768]) tensor([ 0.5412, -0.2970, -0.4073,  0.3460, -0.2974,  0.4035,  0.0176,  0.2931,\n",
    "#          0.2445, -0.1061], grad_fn=<SliceBackward>)\n",
    "\n",
    "# transformer.layer.0.attention.k_lin.weight torch.Size([768, 768]) tensor([ 0.0342, -0.0546, -0.0055,  0.0043,  0.0282, -0.0536,  0.0542,  0.0100,\n",
    "#         -0.0263,  0.0193], grad_fn=<SliceBackward>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight torch.Size([30522, 768]) True\n",
      "embeddings.position_embeddings.weight torch.Size([512, 768]) True\n",
      "embeddings.LayerNorm.weight torch.Size([768]) True\n",
      "embeddings.LayerNorm.bias torch.Size([768]) True\n",
      "transformer.layer.0.attention.q_lin.weight torch.Size([768, 768]) True\n",
      "transformer.layer.0.attention.q_lin.bias torch.Size([768]) True\n",
      "transformer.layer.0.attention.k_lin.weight torch.Size([768, 768]) True\n",
      "transformer.layer.0.attention.k_lin.bias torch.Size([768]) True\n",
      "transformer.layer.0.attention.v_lin.weight torch.Size([768, 768]) True\n",
      "transformer.layer.0.attention.v_lin.bias torch.Size([768]) True\n",
      "transformer.layer.0.attention.out_lin.weight torch.Size([768, 768]) True\n",
      "transformer.layer.0.attention.out_lin.bias torch.Size([768]) True\n",
      "transformer.layer.0.sa_layer_norm.weight torch.Size([768]) True\n",
      "transformer.layer.0.sa_layer_norm.bias torch.Size([768]) True\n",
      "transformer.layer.0.ffn.lin1.weight torch.Size([3072, 768]) True\n",
      "transformer.layer.0.ffn.lin1.bias torch.Size([3072]) True\n",
      "transformer.layer.0.ffn.lin2.weight torch.Size([768, 3072]) True\n",
      "transformer.layer.0.ffn.lin2.bias torch.Size([768]) True\n",
      "transformer.layer.0.output_layer_norm.weight torch.Size([768]) True\n",
      "transformer.layer.0.output_layer_norm.bias torch.Size([768]) True\n",
      "transformer.layer.1.attention.q_lin.weight torch.Size([768, 768]) True\n"
     ]
    }
   ],
   "source": [
    "for p in params[:21]:\n",
    "    print(p[0], p[1].size(), p[1].requires_grad)\n",
    "#     print(p[1])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FtDistilBert(nn.Module):\n",
    "    def __init__(self, hidden_size=768, num_labels=133, dropout_prob=0.5):\n",
    "        super(FtDistilBert, self).__init__()\n",
    "        self.distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.pre_classifier = nn.Linear(hidden_size, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.distilbert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = outputs[0]  # (bs, seq_len, hidden_size)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, hidden_size)\n",
    "        pooled_output = F.relu(self.pre_classifier(pooled_output))  # (bs, hidden_size)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "    \n",
    "model_path = './ft_distilbert_0219.pt'\n",
    "pmodel = FtDistilBert()\n",
    "pmodel.load_state_dict(torch.load(model_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppparams = list(pmodel.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert_model.embeddings.word_embeddings.weight torch.Size([30522, 768]) True\n",
      "distilbert_model.embeddings.position_embeddings.weight torch.Size([512, 768]) True\n",
      "distilbert_model.embeddings.LayerNorm.weight torch.Size([768]) True\n",
      "distilbert_model.embeddings.LayerNorm.bias torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.0.attention.q_lin.weight torch.Size([768, 768]) True\n",
      "distilbert_model.transformer.layer.0.attention.q_lin.bias torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.0.attention.k_lin.weight torch.Size([768, 768]) True\n",
      "distilbert_model.transformer.layer.0.attention.k_lin.bias torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.0.attention.v_lin.weight torch.Size([768, 768]) True\n",
      "distilbert_model.transformer.layer.0.attention.v_lin.bias torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.0.attention.out_lin.weight torch.Size([768, 768]) True\n",
      "distilbert_model.transformer.layer.0.attention.out_lin.bias torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.0.sa_layer_norm.weight torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.0.sa_layer_norm.bias torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.0.ffn.lin1.weight torch.Size([3072, 768]) True\n",
      "distilbert_model.transformer.layer.0.ffn.lin1.bias torch.Size([3072]) True\n",
      "distilbert_model.transformer.layer.0.ffn.lin2.weight torch.Size([768, 3072]) True\n",
      "distilbert_model.transformer.layer.0.ffn.lin2.bias torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.0.output_layer_norm.weight torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.0.output_layer_norm.bias torch.Size([768]) True\n",
      "distilbert_model.transformer.layer.1.attention.q_lin.weight torch.Size([768, 768]) True\n"
     ]
    }
   ],
   "source": [
    "# for p in ppparams[5:21]:\n",
    "#     print(p[0], p[1].size())\n",
    "#     print(p[1])\n",
    "#     break\n",
    "for p in ppparams[:21]:\n",
    "    print(p[0], p[1].size(), p[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertForClassification(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, hidden_size=768, num_labels=133, dropout_prob=0.5):\n",
    "        super().__init__(config)\n",
    "        # self.distilbert = DistilBertModel(config)\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.pre_classifier = nn.Linear(hidden_size, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        # self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None):\n",
    "        distilbert_output = self.distilbert(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        )\n",
    "        hidden_state = distilbert_output[0]  # (bs, seq_len, hidden_size)\n",
    "        pooled_output = hidden_state[:, 0]  # (bs, hidden_size)\n",
    "        pooled_output = F.relu(self.pre_classifier(pooled_output))  # (bs, hidden_size)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "    \n",
    "output_dir = \"./distilbert_models/\"\n",
    "cmodel = DistilBertForClassification.from_pretrained(output_dir)\n",
    "ccparams = list(cmodel.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cmodel.get_output_embeddings()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight torch.Size([30522, 768]) True\n",
      "embeddings.position_embeddings.weight torch.Size([512, 768]) True\n",
      "embeddings.LayerNorm.weight torch.Size([768]) True\n",
      "embeddings.LayerNorm.bias torch.Size([768]) True\n",
      "transformer.layer.0.attention.q_lin.weight torch.Size([768, 768]) True\n",
      "transformer.layer.0.attention.q_lin.bias torch.Size([768]) True\n",
      "transformer.layer.0.attention.k_lin.weight torch.Size([768, 768]) True\n",
      "transformer.layer.0.attention.k_lin.bias torch.Size([768]) True\n",
      "transformer.layer.0.attention.v_lin.weight torch.Size([768, 768]) True\n",
      "transformer.layer.0.attention.v_lin.bias torch.Size([768]) True\n",
      "transformer.layer.0.attention.out_lin.weight torch.Size([768, 768]) True\n",
      "transformer.layer.0.attention.out_lin.bias torch.Size([768]) True\n",
      "transformer.layer.0.sa_layer_norm.weight torch.Size([768]) True\n",
      "transformer.layer.0.sa_layer_norm.bias torch.Size([768]) True\n",
      "transformer.layer.0.ffn.lin1.weight torch.Size([3072, 768]) True\n",
      "transformer.layer.0.ffn.lin1.bias torch.Size([3072]) True\n",
      "transformer.layer.0.ffn.lin2.weight torch.Size([768, 3072]) True\n",
      "transformer.layer.0.ffn.lin2.bias torch.Size([768]) True\n",
      "transformer.layer.0.output_layer_norm.weight torch.Size([768]) True\n",
      "transformer.layer.0.output_layer_norm.bias torch.Size([768]) True\n",
      "transformer.layer.1.attention.q_lin.weight torch.Size([768, 768]) True\n"
     ]
    }
   ],
   "source": [
    "for p in params[:21]:\n",
    "    print(p[0], p[1].size(), p[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charley",
   "language": "python",
   "name": "charley"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}