{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "options_file = \"./small_emlo/elmo_2x1024_128_2048cnn_1xhighway_options.json\"\n",
    "weight_file = \"./small_emlo/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[259,  71, 106, 115, 116, 117, 260, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259, 116, 102, 111, 117, 102, 111, 100, 102, 260, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261]],\n",
       "\n",
       "        [[259,  66, 111, 112, 117, 105, 102, 115, 260, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [259,  47, 260, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261, 261,\n",
       "          261, 261, 261, 261, 261, 261, 261, 261],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  use batch_to_ids to convert sentences to character ids\n",
    "sentences = [['First', 'sentence', '.'], ['Another', '.']]\n",
    "character_ids = batch_to_ids(sentences)\n",
    "print(character_ids.size())\n",
    "character_ids\n",
    "# First : <s>, F, i, r, s, t, </s>\n",
    "# sentence : <s>, s, e, n, t, e, n, c, e, </s>\n",
    "# <s> 259; </s> 260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/16/2019 10:17:05 - INFO - allennlp.modules.elmo -   Initializing ELMo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'elmo_representations': [tensor([[[-0.1290, -0.0053, -0.5269,  ...,  0.1373,  0.2507, -0.7911],\n",
       "           [ 0.5511, -0.2235,  0.1626,  ..., -0.8953,  0.5011, -1.4219],\n",
       "           [ 0.3206,  0.2114,  0.2246,  ..., -0.2516, -0.1505,  0.2238]],\n",
       "  \n",
       "          [[ 0.6634,  0.5339, -0.4762,  ...,  0.2827,  0.2224,  0.0898],\n",
       "           [ 0.0397,  0.2241,  0.1264,  ..., -0.2516, -0.1505,  0.2238],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "         grad_fn=<CopySlices>)], 'mask': tensor([[1, 1, 1],\n",
       "         [1, 1, 0]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo = Elmo(options_file, weight_file, 1, dropout=0)\n",
    "embeddings = elmo(character_ids)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['elmo_representations'][0].size() # batch_size x seq_len x embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['elmo_representations'][0].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/16/2019 10:35:05 - INFO - allennlp.modules.elmo -   Initializing ELMo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo1 = Elmo(options_file, weight_file, 1, dropout=0, requires_grad=False)\n",
    "embeddings1 = elmo1(character_ids)\n",
    "assert embeddings1['elmo_representations'][0].requires_grad == True\n",
    "print([x.requires_grad for x in elmo1._elmo_lstm.parameters()])\n",
    "all(x.requires_grad == False for x in elmo1._elmo_lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([x.requires_grad for x in elmo1.scalar_mix_0.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaination before\n",
    "\n",
    "This is expected. Within the Elmo module, you need a trainable scalar weight matrix that produces a mixtures of the different elmo layers. an operation with a requires_grad=False tensor and a requires_grad=True tensor (the mixture weights) produces the resultant requires_grad=True tensor that you see.\n",
    "\n",
    "The elmo requires_grad construction param should actually be called trainable --- it affects whether the LSTM parameters within the Elmo module get updated during training or not. By passing requires_grad=False into the constructor, we can verify that the LSTM parameters are frozen with:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "# options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "# weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "\n",
    "# elmo = Elmo(options_file, weight_file, 1, dropout=0, requires_grad=False)\n",
    "# all(x.requires_grad == False for x in elmo._elmo_lstm.parameters())\n",
    "# >>>True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/16/2019 09:59:01 - INFO - allennlp.modules.elmo -   Initializing ELMo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ELMoGRU(\n",
       "  (elmo): Elmo(\n",
       "    (_elmo_lstm): _ElmoBiLm(\n",
       "      (_token_embedder): _ElmoCharacterEncoder(\n",
       "        (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "        (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "        (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "        (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "        (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "        (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "        (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "        (_highways): Highway(\n",
       "          (_layers): ModuleList(\n",
       "            (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_projection): Linear(in_features=2048, out_features=128, bias=True)\n",
       "      )\n",
       "      (_elmo_lstm): ElmoLstm(\n",
       "        (forward_layer_0): LstmCellWithProjection(\n",
       "          (input_linearity): Linear(in_features=128, out_features=4096, bias=False)\n",
       "          (state_linearity): Linear(in_features=128, out_features=4096, bias=True)\n",
       "          (state_projection): Linear(in_features=1024, out_features=128, bias=False)\n",
       "        )\n",
       "        (backward_layer_0): LstmCellWithProjection(\n",
       "          (input_linearity): Linear(in_features=128, out_features=4096, bias=False)\n",
       "          (state_linearity): Linear(in_features=128, out_features=4096, bias=True)\n",
       "          (state_projection): Linear(in_features=1024, out_features=128, bias=False)\n",
       "        )\n",
       "        (forward_layer_1): LstmCellWithProjection(\n",
       "          (input_linearity): Linear(in_features=128, out_features=4096, bias=False)\n",
       "          (state_linearity): Linear(in_features=128, out_features=4096, bias=True)\n",
       "          (state_projection): Linear(in_features=1024, out_features=128, bias=False)\n",
       "        )\n",
       "        (backward_layer_1): LstmCellWithProjection(\n",
       "          (input_linearity): Linear(in_features=128, out_features=4096, bias=False)\n",
       "          (state_linearity): Linear(in_features=128, out_features=4096, bias=True)\n",
       "          (state_projection): Linear(in_features=1024, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (_dropout): Dropout(p=0)\n",
       "    (scalar_mix_0): ScalarMix(\n",
       "      (scalar_parameters): ParameterList(\n",
       "          (0): Parameter containing: [torch.FloatTensor of size 1]\n",
       "          (1): Parameter containing: [torch.FloatTensor of size 1]\n",
       "          (2): Parameter containing: [torch.FloatTensor of size 1]\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gru): GRU(256, 256, bidirectional=True)\n",
       "  (dropout2): Dropout(p=0.5)\n",
       "  (fc): Linear(in_features=512, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from elmo_newspaper import ELMoGRU\n",
    "\n",
    "\n",
    "options_file = \"./small_emlo/elmo_2x1024_128_2048cnn_1xhighway_options.json\"\n",
    "weight_file = \"./small_emlo/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\"\n",
    "    \n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ELMoGRU(device, options_file, weight_file, batch_size=8)\n",
    "model.load_state_dict(torch.load(\"elmo_newspaper_0115.pt\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmo._elmo_lstm._token_embedder._char_embedding_weights \t torch.Size([262, 16])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_0.weight \t torch.Size([32, 16, 1])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_0.bias \t torch.Size([32])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_1.weight \t torch.Size([32, 16, 2])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_1.bias \t torch.Size([32])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_2.weight \t torch.Size([64, 16, 3])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_2.bias \t torch.Size([64])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_3.weight \t torch.Size([128, 16, 4])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_3.bias \t torch.Size([128])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_4.weight \t torch.Size([256, 16, 5])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_4.bias \t torch.Size([256])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_5.weight \t torch.Size([512, 16, 6])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_5.bias \t torch.Size([512])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_6.weight \t torch.Size([1024, 16, 7])\n",
      "elmo._elmo_lstm._token_embedder.char_conv_6.bias \t torch.Size([1024])\n",
      "elmo._elmo_lstm._token_embedder._highways._layers.0.weight \t torch.Size([4096, 2048])\n",
      "elmo._elmo_lstm._token_embedder._highways._layers.0.bias \t torch.Size([4096])\n",
      "elmo._elmo_lstm._token_embedder._projection.weight \t torch.Size([128, 2048])\n",
      "elmo._elmo_lstm._token_embedder._projection.bias \t torch.Size([128])\n",
      "elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight \t torch.Size([4096, 128])\n",
      "elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight \t torch.Size([4096, 128])\n",
      "elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias \t torch.Size([4096])\n",
      "elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight \t torch.Size([128, 1024])\n",
      "elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight \t torch.Size([4096, 128])\n",
      "elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight \t torch.Size([4096, 128])\n",
      "elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias \t torch.Size([4096])\n",
      "elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight \t torch.Size([128, 1024])\n",
      "elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight \t torch.Size([4096, 128])\n",
      "elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight \t torch.Size([4096, 128])\n",
      "elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias \t torch.Size([4096])\n",
      "elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight \t torch.Size([128, 1024])\n",
      "elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight \t torch.Size([4096, 128])\n",
      "elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight \t torch.Size([4096, 128])\n",
      "elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias \t torch.Size([4096])\n",
      "elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight \t torch.Size([128, 1024])\n",
      "elmo.scalar_mix_0.gamma \t torch.Size([1])\n",
      "elmo.scalar_mix_0.scalar_parameters.0 \t torch.Size([1])\n",
      "elmo.scalar_mix_0.scalar_parameters.1 \t torch.Size([1])\n",
      "elmo.scalar_mix_0.scalar_parameters.2 \t torch.Size([1])\n",
      "gru.weight_ih_l0 \t torch.Size([768, 256])\n",
      "gru.weight_hh_l0 \t torch.Size([768, 256])\n",
      "gru.bias_ih_l0 \t torch.Size([768])\n",
      "gru.bias_hh_l0 \t torch.Size([768])\n",
      "gru.weight_ih_l0_reverse \t torch.Size([768, 256])\n",
      "gru.weight_hh_l0_reverse \t torch.Size([768, 256])\n",
      "gru.bias_ih_l0_reverse \t torch.Size([768])\n",
      "gru.bias_hh_l0_reverse \t torch.Size([768])\n",
      "fc.weight \t torch.Size([20, 512])\n",
      "fc.bias \t torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, '\\t', model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['fc.weight'].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "charley",
   "language": "python",
   "name": "charley"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
